{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 针对专业人员的 TensorFlow 2.0 入门\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  将 Tensorflow 导入您的程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载并准备 MNIST 数据集。\n",
    "在这一步中，会报错，因此将mnist数据集存储至本地。另寻方法加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ym_load_data(data_folder):\n",
    "    '''\n",
    "    ---定义加载数据的函数，data_folder为保存gz数据的文件夹，该文件夹下有4个文件\n",
    "    ---p:data_folder：数据集路径\n",
    "    '''\n",
    "\n",
    "    files = [\n",
    "      'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "      't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz'\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "    for fname in files:\n",
    "        paths.append(os.path.join(data_folder,fname))\n",
    "\n",
    "    with gzip.open(paths[0], 'rb') as lbpath:\n",
    "        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(paths[1], 'rb') as imgpath:\n",
    "        x_train = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)\n",
    "\n",
    "    with gzip.open(paths[2], 'rb') as lbpath:\n",
    "        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(paths[3], 'rb') as imgpath:\n",
    "        x_test = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_test), 28, 28)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = ym_load_data(r'E:\\a_code_place\\data\\mnist')\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加一个通道维度\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 tf.data 来将数据集切分为 batch 以及混淆数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(10000).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 Keras 模型子类化（model subclassing） API 构建 tf.keras 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为训练选择优化器与损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择衡量指标来度量模型的损失值（loss）和准确率（accuracy）。这些指标在 epoch 上累积值，然后打印出整体结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 tf.GradientTape 来训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loos = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loos)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13752204179763794, Accuracy: 95.88500213623047, Test Loss: 0.06009141355752945, Test Accuracy: 97.89999389648438\n",
      "Epoch 2, Loss: 0.04296257346868515, Accuracy: 98.66999816894531, Test Loss: 0.050236549228429794, Test Accuracy: 98.29999542236328\n",
      "Epoch 3, Loss: 0.023720810189843178, Accuracy: 99.22500610351562, Test Loss: 0.0523027703166008, Test Accuracy: 98.47000122070312\n",
      "Epoch 4, Loss: 0.013968967832624912, Accuracy: 99.53333282470703, Test Loss: 0.050709422677755356, Test Accuracy: 98.54999542236328\n",
      "Epoch 5, Loss: 0.008814689703285694, Accuracy: 99.71666717529297, Test Loss: 0.06438631564378738, Test Accuracy: 98.3499984741211\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # reset\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
